{"cells":[{"cell_type":"markdown","metadata":{"id":"RjYUu_nlHKxo"},"source":["# Notebook Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1638676404135,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"a-g5wfrEHUSN","outputId":"c8164820-10fc-48a8-9876-58f25b2cbac7"},"outputs":[],"source":["import h5py\n","print(h5py.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":114,"status":"ok","timestamp":1638676404925,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"f8BxG6yh1ZL_"},"outputs":[],"source":["# !pip install 'h5py==2.10.0' --force-reinstall"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1638579698557,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"MgrZh7JAG5or","outputId":"87145d47-d0b6-4cae-c9bc-99bbce8d1814"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1638211838472,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"8mlQWMMBGNrG","outputId":"27a76cae-4624-4ca2-97db-689e55f3eb3e"},"outputs":[],"source":["# mount gdrive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1638676411255,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"h-vwmMLzHQzS","outputId":"e4836240-e80c-440a-ef2c-a9a64e41851e"},"outputs":[],"source":["# change directory\n","import os\n","os.chdir('/content/drive/MyDrive/HNN/pet')\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3179,"status":"ok","timestamp":1638676415132,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"bCl8-uRzHbAO","outputId":"0156d06e-49f9-403c-e20e-40025971d9b0"},"outputs":[],"source":["# use tensorflow version 1.15.2\n","%tensorflow_version 1.x\n","\n","# chack compatible keras version\n","import tensorflow as tf\n","print(tf.VERSION)\n","print(tf.keras.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3871,"status":"ok","timestamp":1638676426971,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"F3IvnmZTHkg6","outputId":"f4e08d08-5ce9-4af5-bcd0-98d13742e75b"},"outputs":[],"source":["# install correct keras version (2.2.4)\n","!pip install q keras==2.2.4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1638676429879,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"-ssRWuIcHqP9","outputId":"c6f1ff6e-7b3f-4a67-c0cc-1caff0ff7861"},"outputs":[],"source":["# double check installations\n","import tensorflow as tf \n","import keras \n","print(tf.__version__)\n","print(keras.__version__)"]},{"cell_type":"markdown","metadata":{"id":"kJwiyWlzJDvn"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203,"status":"ok","timestamp":1638654618026,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"INGhUwvBJQzV","outputId":"ca434355-dbcc-452c-8f61-cf888759dcb3"},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1638676432985,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"SB1u60zXJttp"},"outputs":[],"source":["# add pet module to the system path\n","import sys\n","sys.path.append('/content/drive/My Drive/HNN')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2785,"status":"ok","timestamp":1638676436384,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"_XqV0Lr1JFmE"},"outputs":[],"source":["import time\n","import pprint\n","import pickle\n","import os, sys\n","import pandas as pd\n","import random\n","from keras import backend as K\n","from keras.layers import Input\n","from keras.optimizers import Adam\n","from keras.utils import generic_utils\n","from keras.models import Model\n","import tensorflow.keras.backend as K\n","\n","from pet.config import Config\n","from pet.parser import get_data\n","from pet.data_generators import get_anchor_gt\n","from pet.vgg import get_img_output_length, nn_base, rpn_layer, classifier_layer\n","from pet.losses import *\n","from pet.general import *\n","from pet.roi_helpers import rpn_to_roi, calc_iou"]},{"cell_type":"markdown","metadata":{"id":"6bePPHRoH3LB"},"source":["# Training configs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1638676438030,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"KcZPumxRHz6V"},"outputs":[],"source":["# 1. create parameters\n","this_model_name = 'model_2_classes_2'\n","# path that contains the annotation text file\n","train_path = '../data/pet_brain/train_annotate.txt'\n","\n","# number of ROI's to process at once\n","num_rois = 4\n","# Augmentation flag\n","horizontal_flips = True  # Augment with horizontal flips in training.\n","vertical_flips = True  # Augment with vertical flips in training.\n","rot_90 = True  # Augment with 90 degree rotations in training.\n","\n","# location to save the trained model weights\n","output_weight_path = f'../trained_models/faster_rcnn/{this_model_name}'\n","# record data path - used to save losses, classification accuracy, and mean average precision\n","record_path = f'../trained_models/faster_rcnn/{this_model_name}/record.csv'\n","# base weight path\n","base_weight_path = f'../trained_models/faster_rcnn/{this_model_name}/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n","# config file name\n","config_output_filename = f'../trained_models/faster_rcnn/{this_model_name}/model_vgg_config.pickle'\n","\n","model_path = f'../trained_models/faster_rcnn/{this_model_name}/{this_model_name}.hdf5'"]},{"cell_type":"markdown","metadata":{"id":"We0UXRzUIm7q"},"source":["Configure parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":142,"status":"ok","timestamp":1638676447280,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"n90LB501ImZ8"},"outputs":[],"source":["# 2. create the config class instance\n","C = Config()\n","\n","C.use_horizontal_flips = horizontal_flips\n","C.use_vertical_flips = vertical_flips\n","C.rot_90 = rot_90\n","\n","C.record_path = record_path\n","C.model_path = output_weight_path\n","C.num_rois = num_rois\n","# C.anchor_box_scales = [32, 64, 128]\n","\n","C.base_net_weights = base_weight_path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149244,"status":"ok","timestamp":1638676598995,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"cEEt2LWsJAgM","outputId":"726691ad-fa0c-412c-e76c-6039be5de9cf"},"outputs":[],"source":["# 3. load the data\n","st = time.time()\n","train_imgs, classes_count, class_mapping = get_data(train_path)\n","print()\n","print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )\n","print(train_imgs)\n","\n","if 'bg' not in classes_count:\n","    classes_count['bg'] = 0\n","    class_mapping['bg'] = len(class_mapping)\n","# e.g.\n","#    classes_count: {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745, 'bg': 0}\n","#    class_mapping: {'Person': 0, 'Car': 1, 'Mobile phone': 2, 'bg': 3}\n","C.class_mapping = class_mapping\n","\n","print('Training images per class:')\n","pprint.pprint(classes_count)\n","print('Num classes (including bg) = {}'.format(len(classes_count)))\n","print(class_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":736,"status":"ok","timestamp":1638676602795,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"gTXkEc90Kwna","outputId":"a21742cc-e6f3-41b3-810f-f11aa4f98623"},"outputs":[],"source":["# Save the configuration\n","with open(config_output_filename, 'wb') as config_f:\n","    pickle.dump(C, config_f)\n","    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":128,"status":"ok","timestamp":1638676604354,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"VJZuGz8fLTEg"},"outputs":[],"source":["# Get train data generator which generate X, Y, image_data\n","data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":937},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1638676611689,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"-Qcdywa3K-jD","outputId":"3d7a868a-deec-464d-99ad-2d387c9b72e0"},"outputs":[],"source":["# 4. explore the data\n","X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)\n","\n","print('Original image: height=%d width=%d'%(image_data['height'], image_data['width']))\n","print('Resized image:  height=%d width=%d C.im_size=%d'%(X.shape[1], X.shape[2], C.im_size))\n","print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1], Y[0].shape[2], C.rpn_stride))\n","print(X.shape)\n","print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n","print('Shape of y_rpn_cls {}'.format(Y[0].shape))\n","print('Shape of y_rpn_regr {}'.format(Y[1].shape))\n","print(image_data)\n","print('Number of positive anchors for this image: %d' % (debug_num_pos))\n","# draw a sample image\n","draw_sample(C, X, Y, image_data, debug_img, debug_num_pos)"]},{"cell_type":"markdown","metadata":{"id":"TM7Z0imcLeXy"},"source":["# Build the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8912,"status":"ok","timestamp":1638676624046,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"q0wt93p9LK2G","outputId":"d09200e9-fa44-4f6a-d41b-4c607e44f22b"},"outputs":[],"source":["input_shape_img = (None, None, 3)\n","\n","img_input = Input(shape=input_shape_img)\n","roi_input = Input(shape=(None, 4))\n","\n","# define the base network (VGG here, can be Resnet50, Inception, etc)\n","shared_layers = nn_base(img_input, trainable=True)\n","\n","# define the RPN, built on the base layers\n","num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) # 9\n","rpn = rpn_layer(shared_layers, num_anchors)\n","\n","classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n","\n","model_rpn = Model(img_input, rpn[:2])\n","model_classifier = Model([img_input, roi_input], classifier)\n","\n","# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n","model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n","\n","# print(model_all.summary())\n","C.model_path = model_path\n","print(C.model_path)\n","# Because the google colab can only run the session several hours one time (then you need to connect again),\n","# we need to save the model and load the model to continue training\n","if not os.path.isfile(C.model_path):\n","    # If this is the begin of the training, load the pre-traind base network such as vgg-16\n","    try:\n","        print('This is the first time of your training')\n","        print('loading weights from {}'.format(C.base_net_weights))\n","        model_rpn.load_weights(C.base_net_weights, by_name=True)\n","        model_classifier.load_weights(C.base_net_weights, by_name=True)\n","    except:\n","        print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n","            https://github.com/fchollet/keras/tree/master/keras/applications')\n","\n","    # Create the record.csv file to record losses, acc and mAP\n","    record_df = pd.DataFrame(\n","        columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls',\n","                 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n","else:\n","    # If this is a continued training, load the trained model from before\n","    print('Continue training based on previous trained model')\n","    print('Loading weights from {}'.format(C.model_path))\n","    model_rpn.load_weights(C.model_path, by_name=True)\n","    model_classifier.load_weights(C.model_path, by_name=True)\n","\n","    # Load the records\n","    record_df = pd.read_csv(record_path)\n","\n","    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n","    r_class_acc = record_df['class_acc']\n","    r_loss_rpn_cls = record_df['loss_rpn_cls']\n","    r_loss_rpn_regr = record_df['loss_rpn_regr']\n","    r_loss_class_cls = record_df['loss_class_cls']\n","    r_loss_class_regr = record_df['loss_class_regr']\n","    r_curr_loss = record_df['curr_loss']\n","    r_elapsed_time = record_df['elapsed_time']\n","    r_mAP = record_df['mAP']\n","\n","    print('Already train %dK batches' % (len(record_df)))\n","\n","\n","'''LEARNING RATE '''\n","optimizer = Adam(lr=1e-6)\n","optimizer_classifier = Adam(lr=1e-6)\n","model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n","model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n","model_all.compile(optimizer='sgd', loss='mae')\n","\n","print(model_classifier.summary())"]},{"cell_type":"markdown","metadata":{"id":"IZvoI2uPLs1x"},"source":["# Training settings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1638676628434,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"FQ_79EAQLpa_","outputId":"8b0c8e73-478d-4fae-cade-3c2f7c405239"},"outputs":[],"source":["# Training setting\n","total_epochs = len(record_df)\n","r_epochs = len(record_df)\n","\n","epoch_length = 1000\n","num_epochs = 30\n","iter_num = 0\n","\n","total_epochs += num_epochs\n","\n","losses = np.zeros((epoch_length, 5))\n","rpn_accuracy_rpn_monitor = []\n","rpn_accuracy_for_epoch = []\n","\n","if len(record_df)==0:\n","    best_loss = np.Inf\n","else:\n","    best_loss = np.min(r_curr_loss)\n","\n","print(len(record_df))"]},{"cell_type":"markdown","metadata":{"id":"uAhhXLRaL2Lx"},"source":["# Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5378463,"status":"ok","timestamp":1638682011466,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"0nxzltRILyUF","outputId":"d155c18a-9f4f-4153-bb70-ee02e4e263ff"},"outputs":[],"source":["# start training\n","start_time = time.time()\n","for epoch_num in range(num_epochs):\n","    progbar = generic_utils.Progbar(epoch_length)\n","    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n","\n","    r_epochs += 1\n","    \n","    # change LR after some epochs\n","    # K.set_value(model.optimizer.learning_rate, 0.001)\n","\n","# insert While True: here\n","    while True:\n","        try:\n","\n","            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor)) / len(rpn_accuracy_rpn_monitor)\n","                rpn_accuracy_rpn_monitor = []\n","                # print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n","                if mean_overlapping_bboxes == 0:\n","                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n","\n","            # get_updates(params=actor_model.trainable_weights, loss=loss)\n","            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n","            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n","\n","            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n","            loss_rpn = model_rpn.train_on_batch(X, Y)\n","\n","            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n","            P_rpn = model_rpn.predict_on_batch(X)\n","\n","            # R: bboxes (shape=(300,4))\n","            # Convert rpn layer to roi bboxes\n","            # R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n","            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_data_format(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n","\n","            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n","            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n","            # Y1: one hot code for bboxes from above => x_roi (X)\n","            # Y2: corresponding labels and corresponding gt bboxes\n","            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n","\n","            # If X2 is None means there are no matching bboxes\n","            if X2 is None:\n","                rpn_accuracy_rpn_monitor.append(0)\n","                rpn_accuracy_for_epoch.append(0)\n","                continue\n","\n","            # Find out the positive anchors and negative anchors\n","            neg_samples = np.where(Y1[0, :, -1] == 1)\n","            pos_samples = np.where(Y1[0, :, -1] == 0)\n","\n","            if len(neg_samples) > 0:\n","                neg_samples = neg_samples[0]\n","            else:\n","                neg_samples = []\n","\n","            if len(pos_samples) > 0:\n","                pos_samples = pos_samples[0]\n","            else:\n","                pos_samples = []\n","\n","            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n","            rpn_accuracy_for_epoch.append((len(pos_samples)))\n","\n","            if C.num_rois > 1:\n","                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n","                if len(pos_samples) < C.num_rois // 2:\n","                    selected_pos_samples = pos_samples.tolist()\n","                else:\n","                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois // 2, replace=False).tolist()\n","\n","                # Randomly choose (num_rois - num_pos) neg samples\n","                try:\n","                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples),\n","                                                            replace=False).tolist()\n","                except:\n","                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples),\n","                                                            replace=True).tolist()\n","\n","\n","                # Save all the pos and neg samples in sel_samples\n","                sel_samples = selected_pos_samples + selected_neg_samples\n","            else:\n","                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n","                selected_pos_samples = pos_samples.tolist()\n","                selected_neg_samples = neg_samples.tolist()\n","                if np.random.randint(0, 2):\n","                    sel_samples = random.choice(neg_samples)\n","                else:\n","                    sel_samples = random.choice(pos_samples)\n","\n","            # training_data: [X, X2[:, sel_samples, :]]\n","            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n","            #  X                     => img_data resized image\n","            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n","            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n","            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n","\n","            # print(sel_samples)\n","            # xxx = [X, X2[:, sel_samples, :]]\n","            # yyy = [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n","            # print(type(xxx[0]), xxx[0].shape)\n","            # print(type(xxx[1]), xxx[1].shape, xxx[1])\n","            # print(type(yyy[0]), yyy[0].shape)\n","            # print(type(yyy[1]), yyy[1].shape, yyy[1])\n","\n","            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]],\n","                                                         [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n","\n","            #\n","            losses[iter_num, 0] = loss_rpn[1]\n","            losses[iter_num, 1] = loss_rpn[2]\n","\n","            losses[iter_num, 2] = loss_class[1]\n","            losses[iter_num, 3] = loss_class[2]\n","            losses[iter_num, 4] = loss_class[3]\n","            # #\n","            # # print(losses)\n","\n","            iter_num += 1\n","\n","            progbar.update(iter_num,\n","                           [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n","                            ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n","\n","            if iter_num == epoch_length:\n","                loss_rpn_cls = np.mean(losses[:, 0])\n","                loss_rpn_regr = np.mean(losses[:, 1])\n","                loss_class_cls = np.mean(losses[:, 2])\n","                loss_class_regr = np.mean(losses[:, 3])\n","                class_acc = np.mean(losses[:, 4])\n","\n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n","                rpn_accuracy_for_epoch = []\n","\n","                if C.verbose:\n","                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(\n","                        mean_overlapping_bboxes))\n","                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n","                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n","                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n","                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n","                    print('Loss Detector regression: {}'.format(loss_class_regr))\n","                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n","                    print('Elapsed time: {}'.format(time.time() - start_time))\n","                    elapsed_time = (time.time() - start_time) / 60\n","\n","                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n","                iter_num = 0\n","                start_time = time.time()\n","\n","                if curr_loss < best_loss:\n","                    if C.verbose:\n","                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss, curr_loss))\n","                    best_loss = curr_loss\n","                    model_all.save_weights(C.model_path)\n","\n","                new_row = {'mean_overlapping_bboxes': round(mean_overlapping_bboxes, 3),\n","                           'class_acc': round(class_acc, 3),\n","                           'loss_rpn_cls': round(loss_rpn_cls, 3),\n","                           'loss_rpn_regr': round(loss_rpn_regr, 3),\n","                           'loss_class_cls': round(loss_class_cls, 3),\n","                           'loss_class_regr': round(loss_class_regr, 3),\n","                           'curr_loss': round(curr_loss, 3),\n","                           'elapsed_time': round(elapsed_time, 3),\n","                           'mAP': 0}\n","\n","                record_df = record_df.append(new_row, ignore_index=True)\n","                record_df.to_csv(record_path, index=0)\n","                print('*'*100)\n","                break\n","\n","        except Exception as e:\n","            # print('except:  ')\n","            # exc_type, exc_obj, exc_tb = sys.exc_info()\n","            # fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n","            # print(exc_type, fname, exc_tb.tb_lineno)\n","            continue"]},{"cell_type":"markdown","metadata":{"id":"LfejuhL0y5AR"},"source":["# Plot training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1119,"status":"ok","timestamp":1638582763591,"user":{"displayName":"Ahmad Qasem","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05465232592374536821"},"user_tz":360},"id":"y0lz4-BCL8Xe","outputId":"2af3863d-50af-4bbd-c6a1-fc26696eb998"},"outputs":[],"source":["r_epochs = 10\n","record_df = pd.read_csv(C.record_path)\n","\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n","plt.title('mean_overlapping_bboxes')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n","plt.title('class_acc')\n","\n","plt.show()\n","\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n","plt.title('loss_rpn_cls')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n","plt.title('loss_rpn_regr')\n","plt.show()\n","\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n","plt.title('loss_class_cls')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n","plt.title('loss_class_regr')\n","plt.show()\n","\n","plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n","plt.title('total_loss')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FT48FJ-ty8lK"},"outputs":[],"source":["p"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMkMWgVnwEMOuuyl3hGgvSI","machine_shape":"hm","mount_file_id":"1_Yzg5sUaOIt6l9q63iM-fJIAjUK1JBdO","name":"FasterRCNN_train_2_classes.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
